Can a ConvNet see patterns that a human cannot? I am training a ConvNet to detect different types of stripes in my images. As I am working on astronomical images, my pixel values are flux densities and therefore represent ground truth data. When I (as a human) look at my images with the full range (some images have ranges from -10 to 125, others from -0.05 to 3.5, etc...), I can often not detect these stripes. However, when condensing the range to 0 - 1sigma (for x &lt; 0: x=0, and for x > 1sigma: x=1sigma) I can see stripe-type 1. To visually (human) detect stripe-type 2, I need to condense the range to 0 - 3sigma. Now I am fine with doing these preprocessing steps in order to build an adequate and correct training set, but I obviously cannot apply different preprocessings depending on the class on the testing data. So my question is: If I label my training data based on the condensed ranges (where humans can see the stripes), but I train the neural net on the original images (where humans cannot see the stripes due to bad spectral resolution), will the algorithm be able to see the artifacts nevertheless?And how would the fact that ConvNets sometimes \"squash\" the values between 0 and 1 anyways play into this? Or is this only relevant when using sigmoid as an activation function?Do I need to normalize or standardize my images? If I do so and look at the image, it is also nearly impossible to humanly detect the stripes.