Imbalanced Test Data I have an imbalanced (1:5) training and test set with only two classes and have oversampled the training set with SMOTE so that the class ratio is 1:1. The ML model gives values over 0.7 for accuracy, precision, recall, and f1 for the training set. However, since the test set is still imbalanced (1:5), the metrics are still above 0.7 but only because it is performing well on the majority class and failing miserably on the minority class (even though it did okay on the training data). Perhaps it is overfitting and not generalizing well to the test set. Currently, it is able to correctly classify around 6% of the minority class in the test data.Does anybody have any suggestions for building a more robust ML model for document binary classification and, additionally, are there better metrics to use when your test set is imbalanced (i.e., FPR and TPR)?