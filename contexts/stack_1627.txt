Transformer Inefficiency and Heat If a transformer has efficiency of 96%. It means for a 500W capacity and load, the input would be 520W, output 500W so 20W would be emitted as heat.  If load is 250W, then input would be 260W and 10 watts would be emitted as heat. But if there is no load (zero load), how do you compute the wattage that would be lost as heat during the initial stage when magnetic field and flux is being built with no load on the secondary? Is it more than the inefficient percentage lost with load? I'm computing sealed enclosure heat transfer for a design I'm having and I need to know the above.