Understanding training phase of an agent trained using deep Q-learning Assume we have a deterministic game and we want to train an agent using Deep Q-Learning (a.k.a. DQN) to play this game. We record the score of the agent at each episode and plot the scores versus the episode numbers. Assume the maximum score of the game is 1 and the minimum is -1.Now, my question is this: if we trained an agent for 300k episodes and observed after a while the agent learns to get the score of 1 and it keeps doing that for the first 100k. However, after that, the score drops to around -1 and stays there until 300k-th episode. What can be the reason for this phenomena? Although the agent learns to play the game perfectly for a long time, why it suddenly forgets it?