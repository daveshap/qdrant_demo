State-of-the-art algorithms for the training of neural networks with GRU or LSTM units I recently read a lot about neural networks using GRU or LSTM units. There are many easy to use frameworks like tensorflow that do not even require high knowledge about programming. Unfortunately, I never really found good information on how the training of those networks work. Simple backpropagation might probably not work for gated recurrent networks or is just too inefficient for networks with such a high number of variables to learn.So my question is: What are the state-of-the-art algorithms used for the initialization and training of neural networks with GRU or LSTM units? I am not looking for frameworks to use, but for initialization and update equations for the internal parameters.