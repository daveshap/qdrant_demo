K fold cross validation; How many epochs to train for? I am doing k-fold cross validation across my training set with the goal of finding the best structure for a neural network.Within each fold, should I A) train the network for a constant number of epochs? ORB) train each fold until the error on the current fold starts increasing?If I do B) then each parameter set will be trained for different number of epochs. This gives me an additional hyper parameter (number of epochs) which I could use but I am planning on using an additional holdout set to test the performance. Should I then just ignore the number of epochs that the cross validation found and train on the entire training set until the error on the holdout set increases ??