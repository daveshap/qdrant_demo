Relation between the impedance of speaker and amplitude of sin wave? I have an oscillator producing a sine wave with amplitude 3 V (so it oscillates between +3 V and -3 V). The oscillator is at about 500 Hz. I connected this to an 8 ohm speaker and I hear the sound from the oscillator. I noticed that on the speaker is written 0.5W, so I assume that this speaker can handle at most 0.5 W.I am not sure that I understand how speakers work, but applying Ohms law I see that at 3 V and 8 Ohm, the speaker would draw a current of 3/ 8 = 375 mA. This would mean that the power consumed is P = UI = 3x 0.375 = 1.125 W. The speaker is only rated for 0.5 W, so I assume that I should reduce the amplitude if I don't want to damage the speaker.My question is simply: Did I calculate this correctly?(One of my concerns is if I can apply Ohms law since the voltage isn't constant. Could I possibly just add a resistor in series with the speaker to increase the impedance?)