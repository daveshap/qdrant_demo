Fisher LDA - What is the difference between a discriminant function and a linear decision boundary? I am studying Fisher LDA, the case where there are K=2 classes of data.It is my understanding that Fisher LDA looks for the 1-dimensional space onto which the data should be projected in order to maximize the ratio of the between class variance to the within class variance.If this direction is a vector $w$, then how do I compute the linear decision boundary?Many online resources write this as $y(x)=w^{t}x+w_{0}$.If $w$, then isn't $w^{t}x$ the projection of a vector $x$ onto that line? And if so, what is $w_{0}$ and how can one solve for it?I suppose my main question is this: is the decision boundary a function orthogonal to the direction vector that separates data points before projection, or is the decision boundary a point on a line through the vector of maximum separation $w$ that separates the projected points (and if so what is $w_{0}$?