Is life after college just people complaining and working jobs they hate?
Is life after college just people working jobs they hate and complaining about them?

No matter where I go, subway, Cafe, lounge, bar, people are always complaining about things they are involved him.

I was raised never to complain, never to talk bad about others, but it seems people do it so openly.